{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Содержание проекта__\n",
    "\n",
    "[Шаг 1: открываем данные и изучаем общую информацию](#step1)\n",
    "- [Делаем промежуточный вывод](#step1_last)\n",
    "\n",
    "[Шаг 2: разбиваем данные на выборки](#step2)\n",
    "- [Описываем подход](#step2_1)\n",
    "- [Разбиваем на обучающую, валидационную и тестовую выборки](#step2_2)\n",
    "- [Делаем dummy выборку для последующей проверки на адекватность](#step2_3)\n",
    "- [Делаем промежуточный вывод](#step2_last)\n",
    "\n",
    "[Шаг 3: исследуем модели классификации](#step3)\n",
    "- [Модель решающее дерево](#step3_1)\n",
    "- [Модель случайный лес](#step3_2)\n",
    "- [Модель логистическая \"регрессия\"](#step3_3)\n",
    "- [Делаем промежуточный вывод](#step3_last)\n",
    "\n",
    "[Шаг 4: проверьте модель на тестовой выборке](#step4)\n",
    "- [Делаем промежуточный вывод](#step4_last)\n",
    "\n",
    "[Шаг 5: проверьте модели на адекватность](#step5)\n",
    "- [Делаем промежуточный вывод](#step5_last)\n",
    "\n",
    "[Шаг 6: делаем общий вывод](#step6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Импортируем библиотеки, которые нам понядобятся для работы по этому проекту._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "#библиотеки моделей машинного обучения\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from joblib import dump\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/datasets/users_behavior.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3209</td>\n",
       "      <td>122.0</td>\n",
       "      <td>910.98</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35124.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>25.0</td>\n",
       "      <td>190.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3275.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3211</td>\n",
       "      <td>97.0</td>\n",
       "      <td>634.44</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13974.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3212</td>\n",
       "      <td>64.0</td>\n",
       "      <td>462.32</td>\n",
       "      <td>90.0</td>\n",
       "      <td>31239.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3213</td>\n",
       "      <td>80.0</td>\n",
       "      <td>566.09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29480.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3214 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "0      40.0   311.90      83.0  19915.42         0\n",
       "1      85.0   516.75      56.0  22696.96         0\n",
       "2      77.0   467.66      86.0  21060.45         0\n",
       "3     106.0   745.53      81.0   8437.39         1\n",
       "4      66.0   418.74       1.0  14502.75         0\n",
       "...     ...      ...       ...       ...       ...\n",
       "3209  122.0   910.98      20.0  35124.90         1\n",
       "3210   25.0   190.36       0.0   3275.61         0\n",
       "3211   97.0   634.44      70.0  13974.06         0\n",
       "3212   64.0   462.32      90.0  31239.78         0\n",
       "3213   80.0   566.09       6.0  29480.52         1\n",
       "\n",
       "[3214 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1_last'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод:\n",
    "Мы открыли и изучили файл - предобработка данных не требуется. С файлом можно работать дальше, чтобы решить основную задачу построения рекомендательной модели тарифа.\n",
    "___\n",
    "В файле представлены следующие `признаки`. \n",
    "- сalls — количество звонков,\n",
    "- minutes — суммарная длительность звонков в минутах,\n",
    "- messages — количество sms-сообщений,\n",
    "- mb_used — израсходованный интернет-трафик в Мб,\n",
    "- is_ultra — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0).\n",
    "___\n",
    "\n",
    "Целевой признак - `is_ultra`, его обозначим как `target`.\n",
    "Все остальные признаки обозначим как `features`.\n",
    "___\n",
    "Нам необходимо разбить модель по соотношению 3/1/1 на 3 выборки: обучающую, валидационну и тестовую.\n",
    "__Займемся этим в следующем разделе.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Разбейте данные на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Текущая задача машинного обучения из разряда __обучение с учителем__ поскольку нам известен целевой признак. И это __задача классификации__, поскольку целевой признак из двух типов `ultra` или `smart`. А так как спрятанной тестовой выборки нет, то мы разбиваем исходные данные в соотношении __3/1/1__._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Общая выборка состоит из 3214 объектов.\n",
      "\n",
      "Значит, наша обучающая выборка должна быть 60%: 1928 объектов\n",
      "Валидационная выборка должна быть 20%: 643 объектов\n",
      "Тестовая выборка должна быть 20%: 643 объектов\n"
     ]
    }
   ],
   "source": [
    "print(\"Общая выборка состоит из {} объектов.\". format(round(len(data))))\n",
    "print()\n",
    "print(\"Значит, наша обучающая выборка должна быть 60%: {} объектов\".format(round(len(data)*0.6)))\n",
    "print(\"Валидационная выборка должна быть 20%: {} объектов\".format(round(len(data)*0.2)))\n",
    "print(\"Тестовая выборка должна быть 20%: {} объектов\".format(round(len(data)*0.2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Сначала разобьем выборку используя метод из библиотеки `sklearn`, чтобы выделить валидационную выборку и совместно тестовую и обучающую. Потом повторно используем этот же метод для финального разделения на тестовую и обучающую выборки._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_plus_test, data_valid = train_test_split(data, test_size=0.2, random_state=12345)\n",
    "data_train, data_test = train_test_split(data_train_plus_test, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Проверим получились ли у нас запланированные длины выборок._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: 1928 объектов\n",
      "Валидационная выборка: 643 объектов\n",
      "Тестовая выборка: 643 объектов\n"
     ]
    }
   ],
   "source": [
    "print(\"Обучающая выборка: {} объектов\".format(len(data_train)))\n",
    "print(\"Валидационная выборка: {} объектов\".format(len(data_valid)))\n",
    "print(\"Тестовая выборка: {} объектов\".format(len(data_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Отделим целевые признаки в каждой из выборок._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = data_train['is_ultra']\n",
    "features_train = data_train.drop('is_ultra', axis = 1)\n",
    "target_valid = data_valid['is_ultra']\n",
    "features_valid = data_valid.drop('is_ultra', axis = 1)\n",
    "target_test = data_test['is_ultra']\n",
    "features_test = data_test.drop('is_ultra', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Составим также `dummy` выборку для последующего сравнения на адекватность. Используем модуль `random` для случайного проставления признака тарифа. Эта модель будет равносильна подкидыванию монетки._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coin_toss\n",
    "target_dummy = []\n",
    "\n",
    "for i in range(len(target_test)):\n",
    "    target_dummy.append(random.randint(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2_last'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод:\n",
    "1. Мы разбили данные на 3 выборки согласно правилу `3/1/1` поскольку у нас нет спрятанной тестовой выборки.\n",
    "1. Мы также добавили `dummy` выборку с целевым признаком (0,1) по тарифу ультра.\n",
    "___\n",
    "Далее исследуем 3 модели классификации:\n",
    "- решающее дерево;\n",
    "- случайный лес;\n",
    "- логистическая регрессия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Исследуйте модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Исследуем 3 вида моделей:_\n",
    "- решающее дерево, \n",
    "- случайный лес, \n",
    "- логистическую регрессию.\n",
    "___\n",
    "_Оценим показатели качества (`accuracy`, `precision`)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Модель _решающее дерево_\n",
    "\n",
    "_Оцениваем влияние на качество (`accuracy`) разную глубину дерева от 1 до 10._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наибольшая точность 'решающего дерева' accuracy: 0.78849 достигается при depth: 5 \n"
     ]
    }
   ],
   "source": [
    "#модель и прогноз\n",
    "accuracy_tree_0 = 0\n",
    "\n",
    "for depth in range(1,11):\n",
    "    model_tree = DecisionTreeClassifier(random_state=12345, max_depth = depth)\n",
    "    model_tree.fit(features_train, target_train)\n",
    "    prediction_tree = model_tree.predict(features_valid)\n",
    "    accuracy_tree_1 = accuracy_score(target_valid, prediction_tree)\n",
    "    if accuracy_tree_1 > accuracy_tree_0:\n",
    "        best_accuracy_tree = accuracy_tree_1\n",
    "        accuracy_tree_0 = accuracy_tree_1\n",
    "        best_depth = depth\n",
    "        joblib.dump(model_tree, 'model_tree.joblib')\n",
    "print(\"Наибольшая точность 'решающего дерева' accuracy: {} достигается при depth: {} \".format(round(best_accuracy_tree,5), best_depth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Оценим показатель качества `precision` для модели решающего дерева с 5ю уровнями и полученной максимальной оценкой `accuracy`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля объектов отмеченных моделью 'решаюшее дерево' как ультра действительно является ультра: 0.67883\n"
     ]
    }
   ],
   "source": [
    "precision_tree = precision_score(target_valid, prediction_tree, average='binary')\n",
    "print(\"Доля объектов отмеченных моделью 'решаюшее дерево' как ультра действительно является ультра:\", round(precision_tree,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Модель _случайный лес_\n",
    "\n",
    "_Оцениваем влияние на качество (`accuracy`) лес с количеством деревьев от 10 до 50 (с шагом 10) и глубиной от 1 до 5._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наибольшая точность 'решающего дерева' accuracy: 0.79471 достигается при depth: 5 и количестве эстиматоров: 30.\n"
     ]
    }
   ],
   "source": [
    "#модель и прогноз\n",
    "accuracy_forest_0 = 0\n",
    "\n",
    "for est in range(10, 51, 10):\n",
    "    for depth in range(1,6):\n",
    "        model_forest = RandomForestClassifier(random_state=123456, n_estimators = est, max_depth = depth)\n",
    "        model_forest.fit(features_train, target_train)\n",
    "        prediction_forest = model_forest.predict(features_valid)\n",
    "        accuracy_forest_1 = accuracy_score(target_valid, prediction_forest)\n",
    "        if accuracy_forest_1 > accuracy_forest_0:\n",
    "            best_accuracy_forest = accuracy_forest_1\n",
    "            accuracy_forest_0 = accuracy_forest_1\n",
    "            best_depth_forest = depth\n",
    "            best_est = est\n",
    "            joblib.dump(model_forest, 'model_forest.joblib')\n",
    "print(\"Наибольшая точность 'решающего дерева' accuracy: {} достигается при depth: {} и количестве эстиматоров: {}.\".format(round(best_accuracy_forest,5), best_depth_forest, best_est))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Оценим показатель качества `precision` для модели случайного леса с 5ю уровнями и 30 эстиматорами и полученной максимальной оценкой `accuracy`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля объектов отмеченных моделью 'случайный лес' как ультра действительно является ультра: 0.76033\n"
     ]
    }
   ],
   "source": [
    "precision_forest = precision_score(target_valid, prediction_forest, average='binary')\n",
    "print(\"Доля объектов отмеченных моделью 'случайный лес' как ультра действительно является ультра:\", round(precision_forest,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Модель _логистическая \"регрессия\"_\n",
    "\n",
    "_Оцениваем влияние на качество (`accuracy`)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность 'логистической модели' accuracy: 0.70295 \n"
     ]
    }
   ],
   "source": [
    "#модель и прогноз\n",
    "warnings.filterwarnings('ignore')\n",
    "model_logistic = LogisticRegression(random_state=1234567)\n",
    "model_logistic.fit(features_train, target_train)\n",
    "prediction_logistic = model_logistic.predict(features_valid)\n",
    "accuracy_logistic = accuracy_score(target_valid, prediction_logistic)\n",
    "joblib.dump(model_logistic, 'model_logistic.joblib')\n",
    "print(\"Точность 'логистической модели' accuracy: {} \".format(round(accuracy_logistic,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Оценим показатель качества `precision` для логистической модели с полученной оценкой `accuracy`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля объектов отмеченных моделью 'случайный лес' как ультра действительно является ультра: 0.69231\n"
     ]
    }
   ],
   "source": [
    "precision_logistic = precision_score(target_valid, prediction_logistic, average='binary')\n",
    "print(\"Доля объектов отмеченных моделью 'случайный лес' как ультра действительно является ультра:\", round(precision_logistic,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Сделаем небольшой dataframe для легкого сравнения моделей_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparision = pd.DataFrame({\"model\": [\"Решающее дерево\", \"Случайный лес\", \"Логистическая\"], \n",
    "                                  \"accuracy_valid\": [best_accuracy_tree, best_accuracy_forest, accuracy_logistic],\n",
    "                                  \"precision_valid\": [precision_tree, precision_forest, precision_logistic]\n",
    "                                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ _ _ _ _ Табл.№1.Сравнение моделей (до)_ _ _ _ _ _ \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "             model  accuracy_valid  precision_valid\n",
      "0  Решающее дерево        0.788491         0.678832\n",
      "1    Случайный лес        0.794712         0.760331\n",
      "2    Логистическая        0.702955         0.692308\n"
     ]
    }
   ],
   "source": [
    "print(\"_ _ _ _ _ Табл.№1.Сравнение моделей (до)_ _ _ _ _ _ \")\n",
    "print(\"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \")\n",
    "print(model_comparision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3_last'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод:\n",
    "- Для каждой из 3х видов моделей мы определили наилучшие `гиперпараметры` перебором разных значений в цикле.\n",
    "___\n",
    "Для \"Решающего дерева\" - максимальное accuracy достигается при `depth` равным 5.\n",
    "Для \"Случайного леса\" - при `depth` также равным 5 и количестве деревьев (`estimators`) 30.\n",
    "Для \"Логистической регрессии\" - гиперпараметры не задаются.\n",
    "___\n",
    "- Сравнение в Таблице №1 выше показывает, что по показателям `accuracy` и `precision` наилучшей из 3х моделей в данном проекте является `Случайный лес`. Дальше продолжим работу с этой моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проверьте модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Для проверки модели `Случайный лес` на тестовой выборке оценим показатель `accuracy` и `precision`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = joblib.load('model_forest.joblib')\n",
    "prediction_forest_test = model_forest.predict(features_test)\n",
    "accuracy_forest_test = accuracy_score(target_test, prediction_forest_test)\n",
    "precision_forest_test = precision_score(target_test, prediction_forest_test, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели на тестовой выборке: 0.77605 Разница с показателем на валидационной выборке: 0.01866\n",
      "Precision модели на тестовой выборке: 0.75926 Разница с показателем на валидационной выборке: 0.00107\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy модели на тестовой выборке:\", round(accuracy_forest_test,5), \"Разница с показателем на валидационной выборке:\", abs(round(accuracy_forest_test-best_accuracy_forest,5)))\n",
    "print(\"Precision модели на тестовой выборке:\", round(precision_forest_test,5), \"Разница с показателем на валидационной выборке:\", abs(round(precision_forest_test-precision_forest,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Проверим также модель `Решающее дерево`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = joblib.load('model_tree.joblib')\n",
    "prediction_tree_test = model_tree.predict(features_test)\n",
    "accuracy_tree_test = accuracy_score(target_test, prediction_tree_test)\n",
    "precision_tree_test = precision_score(target_test, prediction_tree_test, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели на тестовой выборке: 0.75894 Разница с показателем на валидационной выборке: 0.02955\n",
      "Precision модели на тестовой выборке: 0.74725 Разница с показателем на валидационной выборке: 0.06842\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy модели на тестовой выборке:\", round(accuracy_tree_test,5), \"Разница с показателем на валидационной выборке:\", abs(round(accuracy_tree_test-best_accuracy_tree,5)))\n",
    "print(\"Precision модели на тестовой выборке:\", round(precision_tree_test,5), \"Разница с показателем на валидационной выборке:\", abs(round(precision_tree_test-precision_tree,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_И наконец проверим модель `Логистическая регрессия`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_logistic_test = model_logistic.predict(features_test)\n",
    "accuracy_logistic_test = accuracy_score(target_test, prediction_logistic_test)\n",
    "precision_logistic_test = precision_score(target_test, prediction_logistic_test, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy модели на тестовой выборке: 0.69673 Разница с показателем на валидационной выборке: 0.00622\n",
      "Precision модели на тестовой выборке: 0.69231 Разница с показателем на валидационной выборке: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy модели на тестовой выборке:\", round(accuracy_logistic_test,5), \"Разница с показателем на валидационной выборке:\", abs(round(accuracy_logistic_test-accuracy_logistic,5)))\n",
    "print(\"Precision модели на тестовой выборке:\", round(precision_logistic_test,5), \"Разница с показателем на валидационной выборке:\", abs(round(precision_logistic_test-precision_logistic,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Дополним Таблицу №1 выше и создадим Таблицу №2 со сравнением результатов моделй на тестовой выборке_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparision2 = pd.DataFrame({\"model\": [\"Решающее дерево\", \"Случайный лес\", \"Логистическая\"], \n",
    "                                   \"accuracy_test\": [accuracy_tree_test, accuracy_forest_test, accuracy_logistic_test],\n",
    "                                   \"precision_test\": [precision_tree_test, precision_forest_test, precision_logistic_test]\n",
    "                                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ _ _ _ _ Табл.№1.Сравнение моделей (до)_ _ _ _ _ _ \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "             model  accuracy_valid  precision_valid\n",
      "0  Решающее дерево        0.788491         0.678832\n",
      "1    Случайный лес        0.794712         0.760331\n",
      "2    Логистическая        0.702955         0.692308\n",
      "\n",
      "_ _ _ _Табл.№2.Сравнение моделей (после) _ _ _ _\n",
      "_ __ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "             model  accuracy_test  precision_test\n",
      "0  Решающее дерево       0.758942        0.747253\n",
      "1    Случайный лес       0.776050        0.759259\n",
      "2    Логистическая       0.696734        0.692308\n"
     ]
    }
   ],
   "source": [
    "print(\"_ _ _ _ _ Табл.№1.Сравнение моделей (до)_ _ _ _ _ _ \")\n",
    "print(\"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \")\n",
    "print(model_comparision)\n",
    "print()\n",
    "print(\"_ _ _ _Табл.№2.Сравнение моделей (после) _ _ _ _\")\n",
    "print(\"_ __ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\")\n",
    "print(model_comparision2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=30,\n",
       "                       n_jobs=None, oob_score=False, random_state=123456,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Приме.Код от ревьюера\n",
    "model_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод:\n",
    "Мы видим, что `accuracy` и `precision` нашей модели больше целевого значения 0.75, а разница с этими же показателями на валидационной выборке не существенна. __Мы хорошо обучили модель, существенное переобучение/недообучение не наблюдается. :)__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (бонус) Проверьте модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Для проверки модели на адекватность оценим насколько слуйно созданная выборка нулей и единиц `dummy` способна предсказывать тариф_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dummy = accuracy_score(target_test, target_dummy)\n",
    "precision_dummy = precision_score(target_test, target_dummy, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy dummy модели: 0.47123 Разница с показателем модели случайный лес на тестовой выборке: 0.30482\n",
      "Precision dummy модели: 0.28528 Разница с показателем модели случайный лес на тестовой выборке: 0.47398\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy dummy модели:\", round(accuracy_dummy,5), \"Разница с показателем модели случайный лес на тестовой выборке:\", abs(round(accuracy_forest_test-accuracy_dummy,5)))\n",
    "print(\"Precision dummy модели:\", round(precision_dummy,5), \"Разница с показателем модели случайный лес на тестовой выборке:\", abs(round(precision_forest_test-precision_dummy,5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step5_last'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Используем библиотеку DummyClassifier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dummy2 = DummyClassifier(strategy=\"most_frequent\")\n",
    "model_dummy2.fit(features_train, target_train)\n",
    "prediction_dummy2 = model_logistic.predict(features_test)\n",
    "accuracy_dummy2 = accuracy_score(target_test, prediction_dummy2)\n",
    "precision_dummy2 = precision_score(target_test, prediction_dummy2, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy dummy2 модели: 0.69673\n",
      "Precision dummy2 модели: 0.69231\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy dummy2 модели:\", round(accuracy_dummy2, 5))\n",
    "print(\"Precision dummy2 модели:\", round(precision_dummy2, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод:\n",
    "`Dummy модель` не обладает хоть какой нибудь предсказательной силой, поскольку правильно рекомендует тариф только в 49% случаев и попадает в 31% - это эффективность подбрасывания монетки и алгоритм никакой писать не надо.\n",
    "___\n",
    "Конечно же наша модель `Случайный лес` гораздо лучше справляется с рекомендацией тарифа. Правильность (`accuracy`) выше рандомного на 27.6%, а точность (`precision`) выше на 44%. __Еще раз убеждаемся, что модель составлена правильно.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Общий вывод:\n",
    "1. Мы сравнили 3 модели машинного обучения и нашли наилучшую в данной задаче по показателям `accuracy` и `precision` - это модель `Случайный лес` c глубиной дерева 5 и количеством эстиматоров 30.\n",
    "1. Модель справляется с рекомендацией тарифа лучше чем 2 другие: Дерево решения и Логистическая регрессия и что не маловажно гораздо лучше, чем простое подкидывание монетки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Jupyter Notebook открыт\n",
    "- [x] Весь код исполняется без ошибок\n",
    "- [x] Ячейки с кодом расположены в порядке исполнения\n",
    "- [x] Выполнено задание 1: данные загружены и изучены\n",
    "- [x] Выполнено задание 2: данные разбиты на три выборки\n",
    "- [x] Выполнено задание 3: проведено исследование моделей\n",
    "    - [x] Рассмотрено больше одной модели\n",
    "    - [x] Рассмотрено хотя бы 3 значения гипепараметров для какой-нибудь модели\n",
    "    - [x] Написаны выводы по результатам исследования\n",
    "- [x] Выполнено задание 3: Проведено тестирование\n",
    "- [x] Удалось достичь accuracy не меньше 0.75\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
